# AI 代理的记忆
[![Agent Memory](../../../translated_images/zh-CN/lesson-13-thumbnail.959e3bc52d210c64.webp)](https://youtu.be/QrYbHesIxpw?si=qNYW6PL3fb3lTPMk)

在讨论创建 AI 代理的独特优势时，主要讨论两点：调用工具完成任务的能力和随着时间的推移不断改进的能力。记忆是打造能够自我提升、为用户创造更好体验的代理的基础。

本课将探讨 AI 代理的记忆是什么，以及如何管理和利用记忆来提升应用效果。

## 介绍

本课内容包括：

• **理解 AI 代理记忆**：什么是记忆以及它为何对代理至关重要。

• **实现和存储记忆**：为 AI 代理添加记忆能力的实际方法，重点介绍短期和长期记忆。

• **使 AI 代理自我提升**：记忆如何使代理从过去交互中学习并随着时间改进。

## 可用实现

本课包含两个全面的笔记本教程：

• **[13-agent-memory.ipynb](./13-agent-memory.ipynb)**：使用 Mem0 和 Azure AI 搜索结合 Semantic Kernel 框架实现记忆

• **[13-agent-memory-cognee.ipynb](./13-agent-memory-cognee.ipynb)**：使用 Cognee 实现结构化记忆，自动构建基于嵌入的知识图谱，支持图谱可视化和智能检索

## 学习目标

完成本课后，您将能够：

• **区分 AI 代理的各种记忆类型**，包括工作记忆、短期记忆、长期记忆，以及如人格记忆和情景记忆等特殊形式。

• 使用 Semantic Kernel 框架，利用 Mem0、Cognee、白板记忆和 Azure AI 搜索等工具，**为 AI 代理实现和管理短期及长期记忆**。

• 理解自我提升 AI 代理背后的原理，以及健全的记忆管理系统如何助力持续学习和适应。

## 理解 AI 代理记忆

核心上，**AI 代理的记忆指的是允许它们保留和回忆信息的机制**。这些信息可以是对话的具体细节、用户偏好、过去行为，甚至学到的模式。

没有记忆，AI 应用往往是无状态的，即每次交互都从头开始。这会带来重复且令人沮丧的体验，代理“忘记”了之前的上下文或偏好。

### 为什么记忆很重要？

代理的智能深深依赖于其回忆和利用过往信息的能力。记忆使代理能够：

• **反思**：从过去的行为和结果中学习。

• **互动**：在持续对话中维持上下文。

• **主动和反应**：根据历史数据预见需求或恰当响应。

• **自主**：通过调用存储的知识，更独立地运作。

实现记忆的目标是让代理更**可靠且有能力**。

### 记忆类型

#### 工作记忆

把它想象成代理在单个进行中的任务或思考过程中使用的草稿纸。它保存执行下一步所需的即时信息。

对于 AI 代理，工作记忆通常捕获对话中最相关的信息，即使完整聊天记录很长或被截断。它专注于提取关键要素，如需求、方案、决策和行动。

**工作记忆示例**

在旅行预订代理中，工作记忆可能捕获用户当前的请求，例如“我想预订去巴黎的行程”。这一具体需求保存在代理的即时上下文中，以指导当前交互。

#### 短期记忆

这种记忆在单次对话或会话期间保留信息。它是当前聊天的上下文，使代理能够回溯先前对话轮次。

**短期记忆示例**

用户问“飞往巴黎的机票多少钱？”之后又问“那住宿怎么样？”，短期记忆保证代理知道“那”指的是同一对话中的“巴黎”。

#### 长期记忆

这些信息跨多个对话或会话持续存在。它允许代理记住用户偏好、历史交互或长时间积累的常识。这对于个性化至关重要。

**长期记忆示例**

长期记忆可能存储“Ben 喜欢滑雪和户外活动，喜欢山景咖啡，并因过去受伤避免高级滑雪道”。这些从先前交互中学到的信息将影响将来旅行规划中的推荐，实现高度个性化。

#### 人格记忆

这种特殊记忆帮助代理发展一致的“个性”或“角色”。使代理记住关于自身或其预设角色的细节，使互动更流畅且更有针对性。

**人格记忆示例**

如果旅行代理被设计为“滑雪专家”，人格记忆可能强化这一角色，影响其回答风格与专业知识保持一致。

#### 工作流/情景记忆

该记忆存储代理在完成复杂任务中采取的步骤顺序，包括成功与失败。它类似于记住特定“情景”或过去经历，以便从中学习。

**情景记忆示例**

如果代理尝试预订特定航班因无票失败，情景记忆会记录该失败，使代理在后续尝试中尝试替代航班或更智能地告知用户问题。

#### 实体记忆

涉及从对话中提取和记住特定实体（如人、地点或事物）及事件。它使代理构建对讨论关键元素的结构化理解。

**实体记忆示例**

在一次关于过往旅行的对话中，代理可能提取“巴黎”，“埃菲尔铁塔”和“Le Chat Noir 餐厅晚餐”等实体。未来对话时，代理可回忆"Le Chat Noir"并主动提出帮忙预订。

#### 结构化 RAG（检索增强生成）

虽然 RAG 是广义技术，但“结构化 RAG”被强调为强大的记忆技术。它从各种来源（对话、邮件、图片）提取密集结构化信息，用于提升响应的精准度、召回率和速度。不同于仅依赖语义相似度的传统 RAG，结构化 RAG 利用信息本身的结构。

**结构化 RAG 示例**

不仅仅匹配关键词，结构化 RAG 能从邮箱中解析航班详情（目的地、日期、时间、航空公司）并结构化存储，实现精准查询，比如“我周二预订的飞往巴黎的航班是什么？”

## 实现和存储记忆

为 AI 代理实现记忆涉及**记忆管理**的系统化流程，包括生成、存储、检索、集成、更新甚至“遗忘”（删除）信息。检索尤为关键。

### 专用记忆工具

#### Mem0

一种存储和管理代理记忆的专用工具是 Mem0。Mem0 作为持久记忆层，允许代理回忆相关交互、存储用户偏好和事实背景，并随着时间学习成功与失败。这里的思路是将无状态代理转变为有状态代理。

它通过**提取与更新两个阶段的记忆管道**工作。首先，加入代理线程的消息发送到 Mem0 服务，利用大型语言模型（LLM）总结对话历史并提取新记忆。随后通过 LLM 驱动的更新阶段决定是否添加、修改或删除记忆，将其存储在混合数据存储中，可能包含向量库、图数据库和键值数据库。此系统支持多种记忆类型，能整合图形记忆管理实体间关系。

#### Cognee

另一强大方式是使用 **Cognee**，一个开源语义记忆系统，将结构化与非结构化数据转化为可查询的知识图谱，背书为嵌入向量。Cognee 提供**双存储架构**，结合向量相似度搜索和图关系，帮助代理理解信息之间的相似度和概念关联。

它擅长**混合检索**，融合向量相似度、图结构和 LLM 推理——从原始片段查找到图感知问答。系统维持**动态记忆**，不断进化成长，并保持作为一个连通图可查询，支持短期会话上下文和长期持久记忆。

Cognee 笔记本教程（[13-agent-memory-cognee.ipynb](./13-agent-memory-cognee.ipynb)）演示了如何构建统一记忆层，涵盖多样数据源摄取、知识图可视化及多种针对特定代理需求的查询策略。

### 使用 RAG 存储记忆

除 Mem0 这类专用记忆工具外，还可利用强大的搜索服务如 **Azure AI 搜索** 作为存储和检索记忆的后端，特别适用于结构化 RAG。

这能让您的代理基于自有数据提供响应，确保答案更相关准确。Azure AI 搜索适用于存储用户专属旅行记忆、产品目录或任何领域知识。

Azure AI 搜索支持诸如 **结构化 RAG** 等能力，擅长从大量数据集（如对话历史、邮件乃至图片）中提取和检索密集的结构化信息。相比传统文本拆块和嵌入方法，展现“超人般的精准度和召回率”。

## 让 AI 代理自我提升

自我提升代理的常用模式是引入一个**“知识代理”**。该单独代理观察用户与主代理之间的对话。它的职责是：

1. **识别有价值的信息**：判断对话中是否有内容值得保存为通用知识或用户偏好。

2. **提取和总结**：提炼对话中的关键信息或偏好。

3. **存储在知识库中**：将提取信息持久化，通常存储在向量数据库中，以备后续检索。

4. **增强未来查询**：用户发起新查询时，知识代理检索相关存储信息并附加到用户提示，给予主代理关键上下文（类似 RAG）。

### 记忆优化策略

• **延迟管理**：为避免拖慢用户交互，可先用便宜快速的模型快速检测信息是否有保存或检索价值，仅必要时调用更复杂的提取/检索流程。

• **知识库维护**：对于不断增长的知识库，可将不常用的信息转移到“冷存储”以控制成本。

## 关于代理记忆还有更多疑问？

加入 [Azure AI Foundry Discord](https://aka.ms/ai-agents/discord) ，与其他学习者交流，参加办公时间并获得 AI 代理相关问题解答。

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**免责声明**：  
本文件使用人工智能翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 进行翻译。尽管我们努力确保准确性，但请注意，自动翻译可能存在错误或不准确之处。请以原始语言版本的文件为权威来源。对于重要信息，建议使用专业人工翻译。我们不对因使用本翻译内容而产生的任何误解或误释承担责任。
<!-- CO-OP TRANSLATOR DISCLAIMER END -->