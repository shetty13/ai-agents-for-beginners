# AI 에이전트를 위한 메모리  
[![Agent Memory](../../../translated_images/ko/lesson-13-thumbnail.959e3bc52d210c64.webp)](https://youtu.be/QrYbHesIxpw?si=qNYW6PL3fb3lTPMk)

AI 에이전트를 만드는 고유한 이점에 대해 논할 때 주로 두 가지가 언급됩니다: 작업을 완료하기 위해 도구를 호출하는 능력과 시간이 지나면서 개선할 수 있는 능력. 메모리는 사용자를 위한 더 나은 경험을 창출할 수 있는 자기 개선 에이전트를 만드는 기반입니다.

이번 강의에서는 AI 에이전트를 위한 메모리가 무엇인지, 그리고 이를 어떻게 관리하고 애플리케이션에 유용하게 사용할 수 있는지 살펴보겠습니다.

## 소개

이 강의에서는 다음을 다룹니다:

• **AI 에이전트 메모리 이해**: 메모리가 무엇인지, 그리고 에이전트에 왜 필수적인지.

• **메모리 구현 및 저장**: 단기 및 장기 메모리에 중점을 두어 AI 에이전트에 메모리 기능을 추가하는 실용적인 방법.

• **AI 에이전트 자기개선 구현**: 메모리가 과거 상호작용에서 배우고 시간이 지남에 따라 개선하는 방식을 가능하게 하는 방법.

## 이용 가능한 구현

이 강의에는 두 가지 포괄적인 노트북 튜토리얼이 포함되어 있습니다:

• **[13-agent-memory.ipynb](./13-agent-memory.ipynb)**: Mem0와 Azure AI Search를 사용한 Semantic Kernel 프레임워크 기반 메모리 구현

• **[13-agent-memory-cognee.ipynb](./13-agent-memory-cognee.ipynb)**: 임베딩으로 뒷받침되는 지식 그래프를 자동 구축하고 그래프를 시각화하며 지능적 검색을 제공하는 Cognee 구조화 메모리 구현

## 학습 목표

이 강의를 완료하면 다음을 알게 됩니다:

• 작업 메모리, 단기 및 장기 메모리뿐만 아니라 페르소나(persona) 및 에피소드 메모리 같은 전문화된 형태를 포함한 다양한 AI 에이전트 메모리 유형을 구분하는 방법.

• Mem0, Cognee, 화이트보드 메모리와 Azure AI Search 통합 등 도구를 활용하여 Semantic Kernel 프레임워크로 AI 에이전트의 단기 및 장기 메모리를 구현하고 관리하는 방법.

• 자기개선 AI 에이전트의 원리와 견고한 메모리 관리 시스템이 지속적인 학습과 적응에 어떻게 기여하는지 이해하기.

## AI 에이전트 메모리 이해하기

본질적으로, **AI 에이전트 메모리는 정보를 보유하고 회상할 수 있게 하는 메커니즘을 의미합니다**. 이 정보는 대화에 관한 구체적 세부사항, 사용자 선호, 과거 행동 또는 학습된 패턴일 수 있습니다.

메모리가 없으면 AI 애플리케이션은 상태가 없는(stateless) 경우가 많아 각 상호작용이 처음부터 시작됩니다. 이는 에이전트가 이전 맥락이나 선호를 "잊어버리는" 반복적이고 답답한 사용자 경험으로 이어집니다.

### 왜 메모리가 중요한가?

에이전트의 지능은 과거 정보를 회상하고 활용하는 능력과 깊게 연결되어 있습니다. 메모리는 에이전트를 다음과 같이 만듭니다:

• **반영적(reflective)**: 과거 행동과 결과에서 학습함.

• **상호작용적(interactive)**: 진행 중인 대화 맥락을 유지함.

• **능동적 및 반응적(proactive and reactive)**: 과거 데이터를 기반으로 필요를 예상하거나 적절히 대응함.

• **자율적(autonomous)**: 저장된 지식을 활용하여 더 독립적으로 작동함.

메모리 구현의 목표는 에이전트를 더 **신뢰할 수 있고 유능한 상태로 만드는 것**입니다.

### 메모리 유형

#### 작업 메모리 (Working Memory)

작업 메모리는 에이전트가 단일의 진행 중인 작업이나 사고 과정 동안 사용하는 임시 정보지로 생각할 수 있습니다. 다음 단계를 계산하는 데 즉시 필요한 정보를 담고 있습니다.

AI 에이전트에게 작업 메모리는 대화 내에서 가장 관련 있는 정보를 포착합니다. 전체 대화 기록이 길거나 축약되었더라도 핵심 요소인 요구사항, 제안, 결정, 행동 등을 추출하는 데 집중합니다.

**작업 메모리 예시**

여행 예약 에이전트에서 작업 메모리는 사용자의 현재 요청인 "파리 여행을 예약하고 싶어요"를 포착할 수 있습니다. 이 특정 요구사항은 현재 상호작용을 안내하기 위해 즉각적인 맥락에 유지됩니다.

#### 단기 메모리 (Short Term Memory)

이 메모리는 단일 대화나 세션 동안 정보를 유지합니다. 현재 대화의 맥락으로서, 에이전트가 이전 턴을 참조할 수 있게 합니다.

**단기 메모리 예시**

사용자가 "파리행 비행기 비용이 얼마인가요?"라고 물은 후 "거기 숙박은요?"라고 질문하면, 단기 메모리는 "거기"가 "파리"를 가리키는 것임을 같은 대화 내에서 인식하도록 합니다.

#### 장기 메모리 (Long Term Memory)

여러 대화나 세션에 걸쳐 지속되는 정보를 뜻합니다. 사용자 선호, 과거 상호작용, 일반 지식을 기억하게 해줍니다. 개인화에 중요합니다.

**장기 메모리 예시**

장기 메모리는 "벤은 스키와 야외 활동을 즐기고, 산 전망의 커피를 좋아하며, 과거 부상 때문에 고급 스키 슬로프는 피한다"는 사실을 저장할 수 있습니다. 이전 상호작용에서 학습된 이 정보는 향후 여행 계획 세션에서 매우 개인화된 추천에 영향을 미칩니다.

#### 페르소나 메모리 (Persona Memory)

이 전문화된 메모리는 에이전트가 일관된 "성격(persona)"을 개발하도록 돕습니다. 에이전트가 자신이나 역할에 대한 세부사항을 기억하게 해 더욱 원활하고 집중된 상호작용을 가능하게 합니다.

**페르소나 메모리 예시**

여행 에이전트가 "전문 스키 플래너"로 설계되었다면, 페르소나 메모리는 이 역할을 강화하여 전문가의 어조와 지식에 맞는 응답을 유도합니다.

#### 워크플로우/에피소드 메모리 (Workflow/Episodic Memory)

복잡한 작업 중 에이전트가 수행한 일련의 단계들, 성공과 실패를 저장합니다. 특정 "에피소드"나 과거 경험을 기억하여 학습하는 것과 같습니다.

**에피소드 메모리 예시**

에이전트가 특정 비행기 예약을 시도했지만 좌석이 없어서 실패한 경우, 에피소드 메모리는 이 실패를 기록해 이후 시도 때 대체 항공편을 찾거나 사용자에게 더 잘 알릴 수 있게 합니다.

#### 엔티티 메모리 (Entity Memory)

대화에서 사람, 장소, 사물 같은 특정 엔티티와 이벤트를 추출하여 기억합니다. 에이전트가 주요 요소에 대해 구조화된 이해를 구축할 수 있게 합니다.

**엔티티 메모리 예시**

과거 여행에 대한 대화에서 "파리," "에펠탑," "르 샤 누아르 식당에서의 저녁"을 추출할 수 있습니다. 이후 상호작용에서 에이전트는 "르 샤 누아르"를 떠올리고 새로운 예약을 제안할 수 있습니다.

#### 구조화된 RAG (Structured RAG; Retrieval Augmented Generation)

RAG는 더 넓은 기법이지만, "구조화된 RAG"는 강력한 메모리 기술로 강조됩니다. 대화, 이메일, 이미지와 같은 다양한 출처에서 조밀하고 구조화된 정보를 추출하여 정밀도, 재현율, 응답속도를 높입니다. 고전적 RAG가 의미 유사성에만 의존하는 반면, 구조화된 RAG는 정보의 고유 구조를 활용합니다.

**구조화된 RAG 예시**

단순한 키워드 매칭 대신, 구조화된 RAG는 이메일에서 비행 세부사항(목적지, 날짜, 시간, 항공사)을 파싱하여 구조화하여 저장합니다. 이를 통해 "화요일에 파리로 예약한 비행은 무엇인가요?" 같은 정밀한 질의가 가능합니다.

## 메모리 구현 및 저장

AI 에이전트의 메모리 구현은 **메모리 관리**라는 체계적인 프로세스를 포함합니다. 여기에는 생성, 저장, 검색, 통합, 업데이트 및 심지어 "잊기"(또는 삭제)가 포함됩니다. 이 중 검색은 특히 중요합니다.

### 전문화된 메모리 도구

#### Mem0

에이전트 메모리를 저장 및 관리하는 한 방법은 Mem0 같은 전문 도구를 사용하는 것입니다. Mem0는 지속 가능한 메모리 계층으로 작동하여, 에이전트가 관련 상호작용을 회상하고, 사용자 선호와 사실적 맥락을 저장하며, 성공과 실패에서 학습할 수 있게 합니다. 무상태 에이전트가 상태 저장 에이전트로 변하는 개념입니다.

이 시스템은 **추출과 업데이트의 두 단계 메모리 파이프라인**으로 운영됩니다. 먼저, 에이전트 스레드에 추가된 메시지가 Mem0 서비스로 전송되어 대화 기록 요약과 신규 메모리 추출을 LLM을 통해 수행합니다. 이후, LLM 주도의 업데이트 단계에서 이 메모리를 추가, 수정 또는 삭제할지 결정하며, 벡터, 그래프, 키-값 데이터베이스를 포함할 수 있는 하이브리드 데이터 저장소에 저장합니다. 다양한 메모리 유형을 지원하며, 엔티티 간 관계 관리를 위한 그래프 메모리도 통합할 수 있습니다.

#### Cognee

또 다른 강력한 접근법은 **Cognee**입니다. 오픈 소스 의미 기반 메모리로, 구조화 및 비구조화 데이터를 임베딩으로 지원되는 질의 가능한 지식 그래프로 변환합니다. Cognee는 벡터 유사성 검색과 그래프 관계를 결합한 **이중 저장소 구조**를 제공하여, 정보 단순 유사성이 아니라 개념 간 관계를 이해하도록 돕습니다.

벡터 유사성, 그래프 구조, LLM 추론을 혼합하는 **하이브리드 검색**에 뛰어나며, 원시 조각 조회에서 그래프 인지 질문 응답까지 지원합니다. 시스템은 연결된 그래프로 쿼리 가능한 살아있는 메모리를 유지하며, 단기 세션 맥락과 장기 지속 메모리를 모두 지원합니다.

Cognee 노트북 튜토리얼([13-agent-memory-cognee.ipynb](./13-agent-memory-cognee.ipynb))은 다양한 데이터 소스 수집, 지식 그래프 시각화, 특정 에이전트 요구에 맞춘 다양한 검색 전략을 통한 질의 예제를 통해 이 통합 메모리 계층 구축을 보여줍니다.

### RAG를 이용한 메모리 저장

Mem0와 같은 전문 메모리 도구 외에도, **Azure AI Search를 메모리 저장 및 검색의 백엔드로 활용할 수 있습니다**, 특히 구조화된 RAG에 적합합니다.

이로 인해 에이전트의 응답을 자체 데이터와 연결시켜 더욱 관련성 높고 정확한 답변이 가능합니다. Azure AI Search는 사용자별 여행 메모리, 제품 카탈로그 또는 도메인별 지식을 저장하는 데 활용 가능합니다.

Azure AI Search는 대화 기록, 이메일, 이미지 같은 대형 데이터 세트에서 조밀하고 구조화된 정보를 추출하고 검색하는 데 탁월한 **구조화된 RAG** 기능을 지원합니다. 전통적인 텍스트 청크 및 임베딩 접근법 대비 "초인적 정밀도와 재현율"을 제공합니다.

## AI 에이전트 자기개선 구현

자기개선 에이전트의 일반적 패턴은 **"지식 에이전트(knowledge agent)"** 도입입니다. 이 별도 에이전트는 사용자와 주요 에이전트 간 대화를 관찰하며 역할은 다음과 같습니다:

1. **가치 있는 정보 식별**: 대화 중 저장할 가치가 있는 일반 지식이나 특정 사용자 선호를 파악.

2. **추출 및 요약**: 대화에서 핵심 학습사항이나 선호를 증류.

3. **지식 베이스에 저장**: 추출 정보를 벡터 데이터베이스 등에 영구 저장하여 이후 검색 가능하게 함.

4. **미래 질의 보강**: 사용자의 새 질의가 시작될 때 저장된 관련 정보를 검색해 사용자 프롬프트에 추가, 주요 에이전트에 중요한 문맥을 제공(RAG와 유사).

### 메모리 최적화

• **지연 시간 관리**: 사용자 상호작용 속도 저하 방지를 위해, 초기에는 저비용, 빠른 모델로 정보 저장 또는 검색 가치 여부를 신속히 확인하고, 필요한 경우에만 복잡한 추출/검색 프로세스를 호출.

• **지식 베이스 유지관리**: 지식 베이스가 커지면 덜 자주 쓰는 정보를 "콜드 스토리지"로 이전하여 비용 관리.

## 에이전트 메모리에 대해 더 궁금한 점이 있나요?

[Azure AI Foundry Discord](https://aka.ms/ai-agents/discord)에 참여해 다른 학습자들과 만나고, 오피스 아워에 참석하며 AI 에이전트 관련 질문에 답변을 받아보세요.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있으나, 자동 번역에는 오류나 부정확성이 포함될 수 있음을 양지해 주시기 바랍니다. 원문은 해당 언어의 원본 문서를 권위 있는 출처로 간주해야 합니다. 중요한 정보의 경우 전문적인 인간 번역을 권장합니다. 본 번역 사용으로 인한 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->